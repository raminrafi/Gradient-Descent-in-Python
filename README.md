# Gradient-Descent-in-Python

Gradient descent is an optimization algorithm that's used when training a machine learning model. It's based on a convex function and tweaks its parameters iteratively to minimize a given function to its local minimum. This project is implementation of Gradient Descent technique in Python.
